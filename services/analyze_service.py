# === ìƒë‹¨ import/ì„¤ì • ì¸ê·¼ì— ì¶”ê°€ ===
import re
import os
import json
from datetime import datetime, timedelta
from dotenv import load_dotenv
from prompts.analyze_prompt import generate_prompt
import openai

# ê¶Œì¥: ê°€ì„±ë¹„+í€„
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # í•„ìš” ì‹œ envë¡œ ë°”ê¿”ì¹˜ê¸°
FALLBACK_MODEL = "gpt-3.5-turbo"  # í´ë°±

# --- ì„¹ì…˜ í¬ë§· íŒŒì„œ ---
SECTION_RE = {
    "interpretation": r"\[ê°ì • í•´ì„\]\s*(.+?)(?=\n\[|$)",
    "insight":        r"\[í•œ ì¤„ í†µì°°\]\s*(.+?)(?=\n\[|$)",
    "tags":           r"\[ê°ì • ë¶„ë¥˜\]\s*(.+?)(?=\n\[|$)",
    "emojis":         r"\[ì´ëª¨ì§€\]\s*(.+?)(?=\n\[|$)",
}

def _clean_fence(s: str) -> str:
    s = s.strip()
    if s.startswith("```"):
        s = re.sub(r"^```[a-zA-Z0-9]*", "", s).strip()
        s = re.sub(r"```$", "", s).strip()
    return s

def _parse_sections(text: str) -> dict:
    def pick(pat):
        m = re.search(pat, text, re.S)
        return (m.group(1).strip() if m else "")

    interpretation = pick(SECTION_RE["interpretation"])
    insight        = pick(SECTION_RE["insight"])
    raw_tags       = pick(SECTION_RE["tags"])
    raw_emojis     = pick(SECTION_RE["emojis"])

    # íƒœê·¸: ì‰¼í‘œ/ê³µë°± êµ¬ë¶„ â†’ ìµœëŒ€ 3ê°œ
    tags = [t.strip() for t in re.split(r"[,\s]+", raw_tags) if t.strip()][:3]
    # ì´ëª¨ì§€: ë¬¸ì ë‹¨ìœ„ ì¶”ì¶œ(ê°„ë‹¨í˜•)
    emojis = [e for e in list(raw_emojis) if e.strip()][:3]

    if len(emojis) < 3:
        emojis += ["ğŸ’¬"] * (3 - len(emojis))

    return {
        "interpretation": interpretation or "ê°ì • í•´ì„ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
        "insight": insight or "ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ì—†ìŒ.",
        "tags": tags or ["ì¤‘ë¦½"],
        "emojis": emojis
    }

def _parse_jsonish(content: str) -> dict | None:
    """```json fenced / ëŠìŠ¨í•œ JSONë„ ìµœëŒ€í•œ íŒŒì‹±"""
    s = _clean_fence(content)
    try:
        obj = json.loads(s)
    except Exception:
        return None

    # í—ˆìš© í‚¤: ì‹ (ìƒˆ)ìŠ¤í‚¤ë§ˆ ìš°ì„ 
    if all(k in obj for k in ("interpretation","insight","tags","emojis")):
        return {
            "interpretation": str(obj.get("interpretation") or "").strip(),
            "insight": str(obj.get("insight") or "").strip(),
            "tags": list(obj.get("tags") or [])[:3],
            "emojis": list(obj.get("emojis") or [])[:3] or ["ğŸ’¬","ğŸ’¬","ğŸ’¬"],
        }

    # êµ¬(ì˜›)ìŠ¤í‚¤ë§ˆ(emotions/reason)ë„ ìˆ˜ìš©
    if "emotions" in obj or "reason" in obj:
        tags = list(obj.get("emotions") or [])[:3]
        reason = str(obj.get("reason") or "").strip()
        emojis = ["ğŸ’¬","ğŸ’¬","ğŸ’¬"]
        return {
            "interpretation": reason or "ê°ì • í•´ì„ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            "insight": (reason[:60] + "...") if reason else "ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ì—†ìŒ.",
            "tags": tags or ["ì¤‘ë¦½"],
            "emojis": emojis
        }

    return None


def analyze_emotion(message: str, relationship: str) -> dict:
    """
    ë°˜í™˜ ìŠ¤í‚¤ë§ˆ(í”„ë¡ íŠ¸ ìµœì¢… ê¸°ëŒ€ì¹˜):
    {
      "interpretation": str,
      "insight": str,
      "tags": List[str](<=3),
      "emojis": List[str](==3)
    }
    """
    prompt = generate_prompt(message, relationship)
    print("ğŸ§ª [PROMPT]\n", prompt)

    def _call(model_name: str):
        return openai.ChatCompletion.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ê°ì • ë¶„ì„ ì „ë¬¸ê°€ë¡œ í–‰ë™í•˜ì„¸ìš”. "
                        "ë°˜ë“œì‹œ ì•„ë˜ ì„¹ì…˜ í˜•ì‹ í˜¹ì€ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n"
                        "1) ì„¹ì…˜ í˜•ì‹:\n"
                        "[ê°ì • í•´ì„]\\n...\\n[í•œ ì¤„ í†µì°°]\\n...\\n[ê°ì • ë¶„ë¥˜]\\nA, B, C\\n[ì´ëª¨ì§€]\\nğŸ§©ğŸ§©ğŸ§©\n"
                        "2) JSON í˜•ì‹:\n"
                        '{"interpretation":"...","insight":"...","tags":["A","B"],"emojis":["ğŸ˜€","...","..."]}'
                    ),
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
            max_tokens=400,
        )

    try:
        # 1ì°¨: ì—…ê·¸ë ˆì´ë“œ ëª¨ë¸
        try:
            response = _call(OPENAI_MODEL)
        except Exception as e1:
            print("[GPT REQUEST ERROR - primary]", str(e1))
            # 2ì°¨: í´ë°±
            response = _call(FALLBACK_MODEL)

        content = response["choices"][0]["message"]["content"].strip()
        print("ğŸ§ª [GPT ì‘ë‹µ]\n", content)

        # ìš°ì„  JSON íŒŒì‹± ì‹œë„ â†’ ì‹¤íŒ¨í•˜ë©´ ì„¹ì…˜ íŒŒì‹±
        parsed = _parse_jsonish(content)
        if not parsed:
            parsed = _parse_sections(content)

        # ê²°ê³¼ ì •ê·œí™”(ë³´í˜¸ë§‰)
        interpretation = (parsed.get("interpretation") or "").strip() or "ê°ì • í•´ì„ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        insight = (parsed.get("insight") or "").strip() or "ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ì—†ìŒ."
        tags = list(parsed.get("tags") or [])[:3]
        emojis = list(parsed.get("emojis") or [])[:3]
        if len(emojis) < 3: emojis += ["ğŸ’¬"] * (3 - len(emojis))
        if not tags: tags = ["ì¤‘ë¦½"]

        return {
            "interpretation": interpretation,
            "insight": insight,
            "tags": tags,
            "emojis": emojis
        }

    except Exception as e:
        print("[GPT REQUEST ERROR - fatal]", str(e))
        # ë°±ì—”ë“œ ì˜ˆì™¸ ì‹œì—ë„ í”„ë¡ íŠ¸ ìŠ¤í‚¤ë§ˆ ìœ ì§€
        return {
            "interpretation": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ë¡œ í•´ì„ì„ ì œê³µí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            "insight": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "tags": ["ì¤‘ë¦½"],
            "emojis": ["ğŸ’¬","ğŸ’¬","ğŸ’¬"]
        }
